set.seed(1)
knn.pred = knn(train.x, test.x, train.y, k = 5)
table(knn.pred, Caravan$Purchase[test])
10/37
knn.pred = knn(train.x, test.x, train.y, k = 7)
table(knn.pred, Caravan$Purchase[test])
x.stand = scale(Caravan[, -86])
train.x = x.stand[train, ]
test.x = x.stand[test, ]
train.y = Caravan[train, 'Purchase']
test.y = Caravan[test, 'Purchase']
set.seed(1)
knn.pred = knn(train.x, test.x, train.y, k = 5)
table(knn.pred, Caravan$Purchase[test])
10/37
knn.pred = knn(train.x, test.x, train.y, k = 6)
table(knn.pred, Caravan$Purchase[test])
2/7
set.seed(1)
knn.pred = knn(train.x, test.x, train.y, k = 5)
table(knn.pred, Caravan$Purchase[test])
10/37
knn.pred = knn(train.x, test.x, train.y, k = 7)
table(knn.pred, Caravan$Purchase[test])
set.seed(1)
knn.pred = knn(train.x, test.x, train.y, k = 5)
table(knn.pred, Caravan$Purchase[test])
10/37
knn.pred = knn(train.x, test.x, train.y, k = 10)
table(knn.pred, Caravan$Purchase[test])
set.seed(1)
knn.pred = knn(train.x, test.x, train.y, k = 5)
table(knn.pred, Caravan$Purchase[test])
10/37
knn.pred = knn(train.x, test.x, train.y, k = 3)
table(knn.pred, Caravan$Purchase[test])
25/121
sum(Caravan[test,'Purchase'])
dim(Caravan[test,])
289/4822
library(keras)
library(tensorflow)
library(ISLR2)
library(ggplot2)
###Default
df = Default
attach(df)
str(df)
sum(is.na(df))
n = nrow(df)
set.seed(5)
ntest = trunc(n/3)
testid = sample(1:n, ntest)
df$student = ifelse(df$student == "Yes",1,0)
df$default = ifelse(df$default == "Yes",1,0)
head(df)
x = scale(model.matrix(default ~ . -1, data = df))
y = df$default
###linear logistic regression
glm.fits = glm(
default ~ student + balance + income, data = default, family = binomial
)
summary(glm.fits)
coef(glm.fits)
glm.probs = predict(glm.fits, type = 'response')
contrasts(default)
glm.pred = rep('No', 10000)
glm.pred[glm.probs > 0.5] = 'Yes'
table(glm.pred, default)
###strong results of 97.32%
mean(glm.pred == default)
######neural net
modnn = keras_model_sequential() %>%
layer_dense(units = 10, activation = 'relu',
input_shape = ncol(x)) %>%
layer_dropout(rate = 0.1) %>%
layer_dense(units = 1)
modnn %>% compile(loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history = modnn %>% fit(
x[-testid, ], y[-testid], epochs = 6, batch_size = 2000,
validation_data = list(x[testid, ], y[testid])
)
plot(history)
npred = predict(modnn, x[testid, ])
mean(abs(y[testid] - npred))
rm(list=ls())
library(ggplot2)
library(cowplot)
library(randomForest)
library(dplyr)
beauty = read.csv('beauty.csv')
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam')
beauty = read.csv('beauty.csv')
beauty = read.csv('BeautyData.csv')
attach(beauty)
lm = lm(Beauty ~., data = beauty)
View(beauty)
lm = lm(CourseEvals ~., data = beauty)
summary(lm)
summary(CourseEvals)
summary(BeautyScore)
sd(BeautyScore)
.30415/.7886476
.30415*.7886476
1.88/.7886476
2.38*.30415
set.seed(9)
train = sample(nrow(beauty),nrow(beauty)*.75)
test = (-train)
btrain = beauty[train,]
btest = beauty[test,]
fit = lm(CourseEvals ~ ., data = btrain)
summary(fit)
##MSE on test data
resid = (CourseEvals[test] - predict(fit,btest))
fit.mse = mean(resid^2)
fit.mse
sqrt(fit.mse)
library('glmnet')
x = model.matrix(crim ~ ., beauty)[,-1]
library('glmnet')
x = model.matrix(CourseEvals ~ ., beauty)[,-1]
y = crim
y = CourseEvals
library('glmnet')
x = model.matrix(CourseEvals ~ ., beauty)[,-1]
y = CourseEvals
##Cross-validation to select the optimal lambda based on training data
cv.ridge = cv.glmnet(x[train,], y[train], alpha = 0)
plot(cv.ridge)
ridgelambda = cv.ridge$lambda.min
ridgelambda
##Ridge model setup using training data
ridge.mod = glmnet(x[train, ], y[train], alpha = 0)
plot(ridge.mod)
##Validating ridge model with test data and best lambda
ridge.pred = predict(ridge.mod, s=ridgelambda, newx = x[test,])
ridge.mse = mean((ridge.pred - y[test])^2)
ridge.mse
sqrt(ridge.mse)
##Lasso model setup using training data
lasso.mod = glmnet(x[train, ], y[train], alpha = 1)
plot(lasso.mod)
##Cross-validation to select the optimal lambda based on training data
cv.lasso = cv.glmnet(x[train,], y[train], alpha = 1)
plot(cv.lasso)
lassolambda = cv.lasso$lambda.min
lassolambda
##Validating lasso model with test data and best lambda
lasso.pred = predict(lasso.mod, s=lassolambda, newx = x[test,])
lasso.mse = mean((lasso.pred - y[test])^2)
lasso.mse
sqrt(lasso.mse)
lasso.coef[2:6,]
##coefficients of lasso model
lasso.coef = predict(lasso.mod, s=lassolambda, type='coefficients')
lasso.coef[2:6,]
###PCR model
library('pls')
set.seed(8)
pcr.fit = pcr(CourseEvals ~ ., data = beauty, subset = train, scale = TRUE, validation = 'CV')
summary(pcr.fit)
validationplot(pcr.fit, val.type = 'MSEP')
##PCR validation with test data - best value of M is 5
pcr.pred = predict(pcr.fit, x[test, ], ncomp = 5)
pcr.mse = mean((pcr.pred - y[test])^2)
pcr.mse
sqrt(pcr.mse)
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam')
house = read.csv('MidCity.csv')
attach(house)
rm(list=ls())
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam')
house = read.csv('MidCity.csv')
attach(house)
house = house[-1]
house$Brick = ifelse(house$Brick == 'Yes',1,0)
str(house)
house$Modern = ifelse(house$Nbhd == 3, 1,0)
str(house)
#simple multiple regression
lm = lm(Price ~., data = house)
summary(lm)
rm(list=ls())
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam')
house = read.csv('MidCity.csv')
attach(house)
#remove house ID (unimportant - not a feature)
house = house[-1]
#turn brick into a dummy variable
house$Brick = ifelse(house$Brick == 'Yes',1,0)
#add dummy variable for modern vs old (for neighborhood 3)
#simple multiple regression
lm = lm(Price ~., data = house)
summary(lm)
rm(list=ls())
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam')
house = read.csv('MidCity.csv')
attach(house)
#remove house ID (unimportant - not a feature)
house = house[-1]
#turn brick into a dummy variable
house$Brick = ifelse(house$Brick == 'Yes',1,0)
#add dummy variable for modern vs old (for neighborhood 3)
house$Modern = ifelse(house$Nbhd == 3, 1,0)
str(house)
#simple multiple regression
lm = lm(Price ~., data = house)
summary(lm)
#simple multiple regression
lm = lm(Price ~., data = house)
summary(lm)
set.seed(9)
train = sample(nrow(house),nrow(house)*.75)
test = (-train)
htrain = house[train,]
htest = house[test,]
fit = lm(Price ~ ., data = htrain)
summary(fit)
resid = (Price[test] - predict(fit,htest))
fit.mse = mean(resid^2)
fit.mse
sqrt(fit.mse)
library('glmnet')
x = model.matrix(Price ~ ., house)[,-1]
y = Price
##Cross-validation to select the optimal lambda based on training data
cv.ridge = cv.glmnet(x[train,], y[train], alpha = 0)
plot(cv.ridge)
ridgelambda = cv.ridge$lambda.min
ridgelambda
##Ridge model setup using training data
ridge.mod = glmnet(x[train, ], y[train], alpha = 0)
plot(ridge.mod)
##Validating ridge model with test data and best lambda
ridge.pred = predict(ridge.mod, s=ridgelambda, newx = x[test,])
ridge.mse = mean((ridge.pred - y[test])^2)
ridge.mse
sqrt(ridge.mse)
##Lasso model setup using training data
lasso.mod = glmnet(x[train, ], y[train], alpha = 1)
plot(lasso.mod)
##Cross-validation to select the optimal lambda based on training data
cv.lasso = cv.glmnet(x[train,], y[train], alpha = 1)
plot(cv.lasso)
lassolambda = cv.lasso$lambda.min
lassolambda
##Validating lasso model with test data and best lambda
lasso.pred = predict(lasso.mod, s=lassolambda, newx = x[test,])
lasso.mse = mean((lasso.pred - y[test])^2)
lasso.mse
sqrt(lasso.mse)
lasso.coef[2:8,]
lasso.coef = predict(lasso.mod, s=lassolambda, type='coefficients')
lasso.coef[2:8,]
###PCR model
library('pls')
set.seed(8)
pcr.fit = pcr(Price ~ ., data = house, subset = train, scale = TRUE, validation = 'CV')
summary(pcr.fit)
validationplot(pcr.fit, val.type = 'MSEP')
##PCR validation with test data - best value of M is 5
pcr.pred = predict(pcr.fit, x[test, ], ncomp = 5)
pcr.mse = mean((pcr.pred - y[test])^2)
pcr.mse
sqrt(pcr.mse)
rm(list=ls())
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam')
house = read.csv('MidCity.csv')
attach(house)
#remove house ID (unimportant - not a feature)
house = house[-1]
#turn brick into a dummy variable
house$Brick = ifelse(house$Brick == 'Yes',1,0)
#add dummy variable for modern vs old (for neighborhood 3)
house$Modern = ifelse(house$Nbhd == 3, 1,0)
str(house)
#simple multiple regression
lm = lm(Price ~., data = house)
summary(lm)
set.seed(9)
train = sample(nrow(house),nrow(house)*.75)
test = (-train)
htrain = house[train,]
htest = house[test,]
fit = lm(Price ~ ., data = htrain)
summary(fit)
##MSE on Training Multiple Regression and Testing
resid = (Price[test] - predict(fit,htest))
fit.mse = mean(resid^2)
fit.mse
sqrt(fit.mse)
library('glmnet')
x = model.matrix(Price ~ ., house)[,-1]
y = Price
##Cross-validation to select the optimal lambda based on training data
cv.ridge = cv.glmnet(x[train,], y[train], alpha = 0)
plot(cv.ridge)
ridgelambda = cv.ridge$lambda.min
ridgelambda
##Ridge model setup using training data
ridge.mod = glmnet(x[train, ], y[train], alpha = 0)
plot(ridge.mod)
##Validating ridge model with test data and best lambda
ridge.pred = predict(ridge.mod, s=ridgelambda, newx = x[test,])
ridge.mse = mean((ridge.pred - y[test])^2)
ridge.mse
sqrt(ridge.mse)
##Lasso model setup using training data
lasso.mod = glmnet(x[train, ], y[train], alpha = 1)
plot(lasso.mod)
##Cross-validation to select the optimal lambda based on training data
cv.lasso = cv.glmnet(x[train,], y[train], alpha = 1)
plot(cv.lasso)
lassolambda = cv.lasso$lambda.min
lassolambda
##Validating lasso model with test data and best lambda
lasso.pred = predict(lasso.mod, s=lassolambda, newx = x[test,])
lasso.mse = mean((lasso.pred - y[test])^2)
lasso.mse
sqrt(lasso.mse)
##coefficients of lasso model
lasso.coef = predict(lasso.mod, s=lassolambda, type='coefficients')
lasso.coef[2:8,]
##With my seed, the number of non-zero coefficient estimates is 14. All but F.Undergrad, Books, Terminal, and perc.alumni.
###PCR model
library('pls')
set.seed(8)
pcr.fit = pcr(Price ~ ., data = house, subset = train, scale = TRUE, validation = 'CV')
summary(pcr.fit)
validationplot(pcr.fit, val.type = 'MSEP')
##PCR validation with test data - best value of M is 5
pcr.pred = predict(pcr.fit, x[test, ], ncomp = 5)
pcr.mse = mean((pcr.pred - y[test])^2)
pcr.mse
sqrt(pcr.mse)
lm.mse
fit.mse
ridge.mse
lasso.mse
pcr.mse
#simple multiple regression
lm = lm(Price ~., data = house)
summary(lm)
##Bagging:
library(randomForest)
set.seed(42)
n = nrow(train)
bag_50 = randomForest(Price ~., data = house, ntree=50, mtry=7)
print(bag_50)
fit.mse
ridge.mse
lasso.mse
pcr.mse
##rerunning regression:
house = house[-1]
lm = lm(Price ~., data = house)
summary(lm)
##brick in neighborhood 3:
modhouse = house['Modern' == 1]
modhouse
##brick in neighborhood 3:
house['Modern'==1]
##brick in neighborhood 3:
house['Modern']==1
modhouse = house[house['Modern'] == 1]
modhouse
modhouse = house[house['Modern'] == 1, ]
modhouse['Modern']
lm2 = lm(Price ~., data = modhouse)
summary(lm)
summary(lm2)
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam')
house = read.csv('MidCity.csv')
attach(house)
#remove house ID (unimportant - not a feature)
house = house[-1]
#turn brick into a dummy variable
house$Brick = ifelse(house$Brick == 'Yes',1,0)
#add dummy variable for modern vs old (for neighborhood 3)
house$Modern = ifelse(house$Nbhd == 3, 1,0)
str(house)
#simple multiple regression
lm = lm(Price ~., data = house)
summary(lm)
##Bagging:
library(randomForest)
set.seed(42)
bag_50 = randomForest(Price ~., data = house, ntree=50, mtry=5)
print(bag_50)
fit.mse
ridge.mse
lasso.mse
pcr.mse
varImpPlot(bag_50)
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam')
beauty = read.csv('BeautyData.csv')
attach(beauty)
lm = lm(CourseEvals ~., data = beauty)
summary(lm)
set.seed(9)
train = sample(nrow(beauty),nrow(beauty)*.75)
test = (-train)
btrain = beauty[train,]
btest = beauty[test,]
fit = lm(CourseEvals ~ ., data = btrain)
summary(fit)
##MSE on Training Multiple Regression and Testing
resid = (CourseEvals[test] - predict(fit,btest))
fit.mse = mean(resid^2)
fit.mse
sqrt(fit.mse)
library('glmnet')
x = model.matrix(CourseEvals ~ ., beauty)[,-1]
y = CourseEvals
##Cross-validation to select the optimal lambda based on training data
cv.ridge = cv.glmnet(x[train,], y[train], alpha = 0)
plot(cv.ridge)
ridgelambda = cv.ridge$lambda.min
ridgelambda
##Ridge model setup using training data
ridge.mod = glmnet(x[train, ], y[train], alpha = 0)
plot(ridge.mod)
##Validating ridge model with test data and best lambda
ridge.pred = predict(ridge.mod, s=ridgelambda, newx = x[test,])
ridge.mse = mean((ridge.pred - y[test])^2)
ridge.mse
sqrt(ridge.mse)
##Lasso model setup using training data
lasso.mod = glmnet(x[train, ], y[train], alpha = 1)
plot(lasso.mod)
##Cross-validation to select the optimal lambda based on training data
cv.lasso = cv.glmnet(x[train,], y[train], alpha = 1)
plot(cv.lasso)
lassolambda = cv.lasso$lambda.min
lassolambda
##Validating lasso model with test data and best lambda
lasso.pred = predict(lasso.mod, s=lassolambda, newx = x[test,])
lasso.mse = mean((lasso.pred - y[test])^2)
lasso.mse
sqrt(lasso.mse)
##coefficients of lasso model
lasso.coef = predict(lasso.mod, s=lassolambda, type='coefficients')
lasso.coef[2:6,]
##With my seed, the number of non-zero coefficient estimates is 14. All but F.Undergrad, Books, Terminal, and perc.alumni.
###PCR model
library('pls')
set.seed(8)
pcr.fit = pcr(CourseEvals ~ ., data = beauty, subset = train, scale = TRUE, validation = 'CV')
summary(pcr.fit)
validationplot(pcr.fit, val.type = 'MSEP')
##PCR validation with test data - best value of M is 5
pcr.pred = predict(pcr.fit, x[test, ], ncomp = 5)
pcr.mse = mean((pcr.pred - y[test])^2)
pcr.mse
sqrt(pcr.mse)
##Bagging:
library(randomForest)
set.seed(42)
bag_50 = randomForest(Price ~., data = house, ntree=50, mtry=5)
print(bag_50)
varImpPlot(bag_50)
fit.mse
ridge.mse
lasso.mse
pcr.mse
##Bagging:
library(randomForest)
set.seed(42)
bag_50 = randomForest(Price ~., data = beauty, ntree=50, mtry=5)
##Bagging:
library(randomForest)
set.seed(42)
bag_50 = randomForest(CourseEvals ~., data = beauty, ntree=50, mtry=5)
print(bag_50)
varImpPlot(bag_50)
fit.mse
ridge.mse
lasso.mse
pcr.mse
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Exam/Markdown')
library(ggplot2)
library(cowplot)
library(randomForest)
library(dplyr)
#Raw data split into about 75/25 training and test.
train = read.csv('Training.csv')
train = train[-5]
test = test[-5]
set.seed(7)
### Recreate validation set
#create validation set separated into 2 sets: x inputs for prediction, y values for validation
pred = subset(test, select = -TripCount)
#Raw data split into about 75/25 training and test.
setwd('C:/Users/Rukh/School/UT/Summer/STA 380/Project')
train = read.csv('Training.csv')
test = read.csv('Test.csv')
train = train[-5]
test = test[-5]
set.seed(7)
#create validation set separated into 2 sets: x inputs for prediction, y values for validation
pred = subset(test, select = -TripCount)
predY = as.double(test$TripCount)
##Validate the bagging model
print('Creating random forest of 150 trees..')
bag2_val_150 = randomForest(TripCount ~., data = train, xtest = pred, ytest = predY, ntree=150, mtry=18)
print(bag2_val_150)
plot(bag2_val_150)
varImpPlot(bag2_val_150)
